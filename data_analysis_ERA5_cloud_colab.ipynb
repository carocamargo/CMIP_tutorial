{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/carocamargo/CMIP_tutorial/blob/main/data_analysis_ERA5_cloud_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data analysis example from: https://theo.earth/whoi-climate-tutorial_2025/pages/data_analysis/example.html"
      ],
      "metadata": {
        "id": "qL4I9YcyUQc3"
      },
      "id": "qL4I9YcyUQc3"
    },
    {
      "cell_type": "markdown",
      "id": "aa9da500-5ed5-4244-85ae-f5b2df368c45",
      "metadata": {
        "id": "aa9da500-5ed5-4244-85ae-f5b2df368c45"
      },
      "source": [
        "# Example\n",
        "In this example, we'll compute climate diagnostics for Woods Hole sea surface temperature (SST) using the ERA5 reanalysis.  \n",
        "{download}`Download notebook<./example.ipynb>`"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "USING_COLAB = True"
      ],
      "metadata": {
        "id": "sVmVvlcSSU9P"
      },
      "id": "sVmVvlcSSU9P",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if USING_COLAB:\n",
        "  #!pip install cartopy cmocean gcsfs zarr\n",
        "  !pip install zarr\n",
        "  #!pip install git+https://github.com/google-research/weatherbench2.git\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_dPavPhMSXdB",
        "outputId": "d85b11ed-778b-4553-d822-720a2e621da2"
      },
      "id": "_dPavPhMSXdB",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: zarr in /usr/local/lib/python3.11/dist-packages (2.18.6)\n",
            "Requirement already satisfied: asciitree in /usr/local/lib/python3.11/dist-packages (from zarr) (0.3.3)\n",
            "Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.11/dist-packages (from zarr) (2.2.6)\n",
            "Requirement already satisfied: fasteners in /usr/local/lib/python3.11/dist-packages (from zarr) (0.19)\n",
            "Requirement already satisfied: numcodecs!=0.14.0,!=0.14.1,>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from zarr) (0.16.1)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.11/dist-packages (from numcodecs!=0.14.0,!=0.14.1,>=0.10.0->zarr) (4.14.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# libraries that are already pre-installed\n",
        "import pathlib\n",
        "import numpy as np\n",
        "import xarray as xr\n",
        "# import cartopy.crs as ccrs\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.dates as mdates\n",
        "import datetime\n",
        "import seaborn as sns\n",
        "import time\n",
        "# import cmocean\n",
        "import matplotlib.patches as mpatches\n",
        "import matplotlib.ticker as mticker\n",
        "import scipy.signal\n",
        "import copy\n",
        "\n",
        "## (optional) remove gridlines from plots\n",
        "sns.set(rc={\"axes.facecolor\": \"white\", \"axes.grid\": False})"
      ],
      "metadata": {
        "id": "0SxHhvwfYNGs"
      },
      "id": "0SxHhvwfYNGs",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load libraries we installed\n",
        "# import cartopy.crs as ccrs\n",
        "# import cmocean"
      ],
      "metadata": {
        "id": "QZwqtTUjSuja"
      },
      "id": "QZwqtTUjSuja",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import apache_beam   # Needs to be imported separately to avoid TypingError\n",
        "import weatherbench2"
      ],
      "metadata": {
        "id": "g7iJWP8ZX8q7"
      },
      "id": "g7iJWP8ZX8q7",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the code below to access cloud data on Colab!\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "metadata": {
        "id": "IF8-6qiHYrSs"
      },
      "id": "IF8-6qiHYrSs",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test using data from cloud\n",
        "forecast_path = 'gs://weatherbench2/datasets/hres/2016-2022-0012-64x32_equiangular_conservative.zarr'\n",
        "obs_path = 'gs://weatherbench2/datasets/era5/1959-2022-6h-64x32_equiangular_conservative.zarr'\n",
        "climatology_path = 'gs://weatherbench2/datasets/era5-hourly-climatology/1990-2019_6h_64x32_equiangular_conservative.zarr'\n",
        "\n",
        "ds = xr.open_zarr(forecast_path)\n",
        "ds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 631
        },
        "id": "_SYwKGklV5OT",
        "outputId": "133eff4a-d328-45f0-b3bf-fa152bff6214"
      },
      "id": "_SYwKGklV5OT",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "The zarr package is required for working with Zarr stores but could not be imported. Please install it with your package manager (e.g. conda or pip).",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/xarray/core/utils.py\u001b[0m in \u001b[0;36mattempt_import\u001b[0;34m(module)\u001b[0m\n\u001b[1;32m   1284\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1285\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1286\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mImportError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModuleNotFoundError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/zarr/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mzarr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcodecs\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m from zarr.convenience import (\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mconsolidate_metadata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/zarr/convenience.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mzarr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdata_root\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta_root\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0massert_zarr_v3_api_available\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mzarr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mArray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/zarr/_storage/store.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mzarr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeta\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMetadata2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMetadata3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mzarr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnormalize_storage_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/zarr/meta.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mzarr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMetadataError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mzarr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjson_dumps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_loads\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/zarr/util.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnumcodecs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregistry\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcodec_registry\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mnumcodecs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblosc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcbuffer_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcbuffer_metainfo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mzarr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtypes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDIMENSION_SEPARATOR\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'cbuffer_sizes' from 'numcodecs.blosc' (/usr/local/lib/python3.11/dist-packages/numcodecs/blosc.cpython-311-x86_64-linux-gnu.so)",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-6-621195182.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mclimatology_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'gs://weatherbench2/datasets/era5-hourly-climatology/1990-2019_6h_64x32_equiangular_conservative.zarr'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_zarr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforecast_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/xarray/backends/zarr.py\u001b[0m in \u001b[0;36mopen_zarr\u001b[0;34m(store, group, synchronizer, chunks, decode_cf, mask_and_scale, decode_times, concat_characters, decode_coords, drop_variables, consolidated, overwrite_encoded_chunks, chunk_store, storage_options, decode_timedelta, use_cftime, zarr_version, zarr_format, use_zarr_fill_value_as_mask, chunked_array_type, from_array_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m   1533\u001b[0m     }\n\u001b[1;32m   1534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1535\u001b[0;31m     ds = open_dataset(\n\u001b[0m\u001b[1;32m   1536\u001b[0m         \u001b[0mfilename_or_obj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstore\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1537\u001b[0m         \u001b[0mgroup\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/xarray/backends/api.py\u001b[0m in \u001b[0;36mopen_dataset\u001b[0;34m(filename_or_obj, engine, chunks, cache, decode_cf, mask_and_scale, decode_times, decode_timedelta, use_cftime, concat_characters, decode_coords, drop_variables, inline_array, chunked_array_type, from_array_kwargs, backend_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m    685\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m     \u001b[0moverwrite_encoded_chunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"overwrite_encoded_chunks\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 687\u001b[0;31m     backend_ds = backend.open_dataset(\n\u001b[0m\u001b[1;32m    688\u001b[0m         \u001b[0mfilename_or_obj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m         \u001b[0mdrop_variables\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdrop_variables\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/xarray/backends/zarr.py\u001b[0m in \u001b[0;36mopen_dataset\u001b[0;34m(self, filename_or_obj, mask_and_scale, decode_times, concat_characters, decode_coords, drop_variables, use_cftime, decode_timedelta, group, mode, synchronizer, consolidated, chunk_store, storage_options, zarr_version, zarr_format, store, engine, use_zarr_fill_value_as_mask, cache_members)\u001b[0m\n\u001b[1;32m   1606\u001b[0m         \u001b[0mfilename_or_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_normalize_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename_or_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1607\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mstore\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1608\u001b[0;31m             store = ZarrStore.open_group(\n\u001b[0m\u001b[1;32m   1609\u001b[0m                 \u001b[0mfilename_or_obj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1610\u001b[0m                 \u001b[0mgroup\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/xarray/backends/zarr.py\u001b[0m in \u001b[0;36mopen_group\u001b[0;34m(cls, store, mode, synchronizer, group, consolidated, consolidate_on_close, chunk_store, storage_options, append_dim, write_region, safe_chunks, zarr_version, zarr_format, use_zarr_fill_value_as_mask, write_empty, cache_members)\u001b[0m\n\u001b[1;32m    730\u001b[0m             \u001b[0mclose_store_on_close\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m             \u001b[0muse_zarr_fill_value_as_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 732\u001b[0;31m         \u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_open_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    733\u001b[0m             \u001b[0mstore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstore\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m             \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/xarray/backends/zarr.py\u001b[0m in \u001b[0;36m_get_open_params\u001b[0;34m(store, mode, synchronizer, group, consolidated, consolidate_on_close, chunk_store, storage_options, zarr_version, use_zarr_fill_value_as_mask, zarr_format)\u001b[0m\n\u001b[1;32m   1765\u001b[0m         \u001b[0;32mimport\u001b[0m \u001b[0mzarr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1766\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1767\u001b[0;31m         \u001b[0mzarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattempt_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"zarr\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1768\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1769\u001b[0m     \u001b[0;31m# zarr doesn't support pathlib.Path objects yet. zarr-python#601\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/xarray/core/utils.py\u001b[0m in \u001b[0;36mattempt_import\u001b[0;34m(module)\u001b[0m\n\u001b[1;32m   1285\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1286\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mImportError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModuleNotFoundError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1287\u001b[0;31m         raise ImportError(\n\u001b[0m\u001b[1;32m   1288\u001b[0m             \u001b[0;34mf\"The {install_name} package is required {reason}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1289\u001b[0m             \u001b[0;34m\" but could not be imported.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: The zarr package is required for working with Zarr stores but could not be imported. Please install it with your package manager (e.g. conda or pip).",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "22ed0dfe-898f-4d37-95f8-c63c16d67b06",
      "metadata": {
        "editable": true,
        "tags": [],
        "id": "22ed0dfe-898f-4d37-95f8-c63c16d67b06"
      },
      "source": [
        "## Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "54e3c29b-d347-47e0-8984-e210a0137011",
      "metadata": {
        "editable": true,
        "tags": [
          "hide-input"
        ],
        "id": "54e3c29b-d347-47e0-8984-e210a0137011"
      },
      "outputs": [],
      "source": [
        "def plot_setup(fig, projection, lon_range, lat_range, xticks=None, yticks=None):\n",
        "    \"\"\"Add a subplot to the figure with the given map projection\n",
        "    and lon/lat range. Returns an Axes object.\"\"\"\n",
        "\n",
        "    ## increase resolution for projection\n",
        "    ## (otherwise lines plotted on surface won't follow curved trajectories)\n",
        "    projection.threshold /= 1000\n",
        "\n",
        "    ## Create subplot with given projection\n",
        "    ax = fig.add_subplot(projection=projection)\n",
        "\n",
        "    ## Subset to given region\n",
        "    extent = [*lon_range, *lat_range]\n",
        "    ax.set_extent(extent, crs=ccrs.PlateCarree())\n",
        "\n",
        "    ## draw coastlines\n",
        "    ax.coastlines(linewidths=0.5)\n",
        "\n",
        "    ## add tick labels\n",
        "    if xticks is not None:\n",
        "\n",
        "        ## add lon/lat labels\n",
        "        gl = ax.gridlines(\n",
        "            draw_labels=True,\n",
        "            linestyle=\"-\",\n",
        "            alpha=0.1,\n",
        "            linewidth=0.5,\n",
        "            color=\"k\",\n",
        "            zorder=1.05,\n",
        "        )\n",
        "\n",
        "        ## specify which axes to label\n",
        "        gl.top_labels = False\n",
        "        gl.right_labels = False\n",
        "\n",
        "        ## specify ticks\n",
        "        gl.ylocator = mticker.FixedLocator(yticks)\n",
        "        gl.xlocator = mticker.FixedLocator(xticks)\n",
        "\n",
        "    return ax\n",
        "\n",
        "\n",
        "def plot_box_outline(ax, lon_range, lat_range):\n",
        "    \"\"\"\n",
        "    Plot box outlining the specifed lon/lat range on given\n",
        "    ax object.\n",
        "    \"\"\"\n",
        "\n",
        "    ## get width and height\n",
        "    height = lat_range[1] - lat_range[0]\n",
        "    width = lon_range[1] - lon_range[0]\n",
        "\n",
        "    ## add rectangle to plot\n",
        "    ax.add_patch(\n",
        "        mpatches.Rectangle(\n",
        "            xy=[lon_range[0], lat_range[0]],\n",
        "            height=height,\n",
        "            width=width,\n",
        "            transform=ccrs.PlateCarree(),\n",
        "            facecolor=\"none\",\n",
        "            edgecolor=\"k\",\n",
        "            linewidth=1,\n",
        "        )\n",
        "    )\n",
        "\n",
        "    return ax\n",
        "\n",
        "\n",
        "def plot_correlation(plot_setup_fn, corr, x, y):\n",
        "    \"\"\"\n",
        "    Make spatial plot of correlation, using the specified\n",
        "    plot setup function and pre-computed correlation.\n",
        "    Args:\n",
        "        - plot_setup_fn: function that returns a fig, ax object\n",
        "        - corr: xarray with spatial correlation\n",
        "        - x, y: lon/lat points for plotting\n",
        "    \"\"\"\n",
        "\n",
        "    ## blank canvas to plot on\n",
        "    fig = plt.figure()\n",
        "\n",
        "    ## draw background map of Atlantic\n",
        "    fig, ax = plot_setup_fn(fig)\n",
        "\n",
        "    ## plot the data\n",
        "    plot_data = ax.contourf(\n",
        "        x,\n",
        "        y,\n",
        "        corr,\n",
        "        transform=ccrs.PlateCarree(),\n",
        "        levels=make_cb_range(1, 0.1),\n",
        "        extend=\"both\",\n",
        "        # cmap=\"cmo.balance\",\n",
        "        cmap=\"seismic\",\n",
        "    )\n",
        "\n",
        "    ## create colorbath\n",
        "    colorbar = fig.colorbar(plot_data, label=\"Corr.\", ticks=[-1, -0.5, 0, 0.5, 1])\n",
        "\n",
        "    return fig, ax\n",
        "\n",
        "\n",
        "def make_cb_range(amp, delta):\n",
        "    \"\"\"Make colorbar_range for cmo.balance\n",
        "    Args:\n",
        "        - 'amp': amplitude of maximum value for colorbar\n",
        "        - 'delta': increment for colorbar\n",
        "    \"\"\"\n",
        "    return np.concatenate(\n",
        "        [np.arange(-amp, 0, delta), np.arange(delta, amp + delta, delta)]\n",
        "    )\n",
        "\n",
        "\n",
        "def plot_setup_timeseries():\n",
        "    \"\"\"\n",
        "    Create fig, ax objects and label time axis\n",
        "    \"\"\"\n",
        "\n",
        "    ## set up plot\n",
        "    fig, ax = plt.subplots(figsize=(4, 3))\n",
        "\n",
        "    ## restrict to last 50 years and label axes\n",
        "    ax.set_xlim([datetime.date(1970, 1, 1), None])\n",
        "\n",
        "    ax.set_xticks(\n",
        "        [\n",
        "            datetime.date(1979, 1, 1),\n",
        "            datetime.date(2000, 6, 30),\n",
        "            datetime.date(2021, 12, 31),\n",
        "        ]\n",
        "    )\n",
        "    ax.xaxis.set_major_formatter(mdates.DateFormatter(\"%Y\"))\n",
        "\n",
        "    return fig, ax\n",
        "\n",
        "\n",
        "def spatial_avg(data):\n",
        "    \"\"\"function to compute spatial average of data on grid with constant\n",
        "    longitude/latitude spacing.\"\"\"\n",
        "\n",
        "    ## first, compute cosine of latitude (after converting degrees to radians)\n",
        "    latitude_radians = np.deg2rad(data.latitude)\n",
        "    cos_lat = np.cos(latitude_radians)\n",
        "\n",
        "    ## get weighted average using xarray\n",
        "    avg = data.weighted(weights=cos_lat).mean([\"longitude\", \"latitude\"])\n",
        "\n",
        "    return avg\n",
        "\n",
        "\n",
        "def get_trend(data, dim=\"time\", deg=1):\n",
        "    \"\"\"\n",
        "    Get trend for an xr.dataarray along specified dimension,\n",
        "    by fitting polynomial of degree 'deg'.\n",
        "    \"\"\"\n",
        "\n",
        "    ## Get coefficients for best fit\n",
        "    polyfit_coefs = data.polyfit(dim=dim, deg=deg)[\"polyfit_coefficients\"]\n",
        "\n",
        "    ## Get best fit line (linear trend in this case)\n",
        "    trend = xr.polyval(data[dim], polyfit_coefs)\n",
        "\n",
        "    return trend\n",
        "\n",
        "\n",
        "def detrend(data, dim=\"time\", deg=1):\n",
        "    \"\"\"\n",
        "    Remove trend of degree 'deg' from data, along dimension 'dim'.\n",
        "    \"\"\"\n",
        "\n",
        "    return data - get_trend(data, dim=dim, deg=deg)\n",
        "\n",
        "\n",
        "def get_empirical_pdf(x):\n",
        "    \"\"\"\n",
        "    Estimate the \"empirical\" probability distribution function for the data x.\n",
        "    In this case the result is a normalized histogram,\n",
        "    Normalized means that integrating over the histogram yields 1.\n",
        "    Returns the PDF (normalized histogram) and edges of the histogram bins\n",
        "    \"\"\"\n",
        "\n",
        "    ## compute histogram\n",
        "    hist, bin_edges = np.histogram(x)\n",
        "\n",
        "    ## normalize to a probability distribution (PDF)\n",
        "    bin_width = bin_edges[1:] - bin_edges[:-1]\n",
        "    pdf = hist / (hist * bin_width).sum()\n",
        "\n",
        "    return pdf, bin_edges\n",
        "\n",
        "\n",
        "def get_gaussian_best_fit(x):\n",
        "    \"\"\"Get gaussian best fit to data, and evaluate\n",
        "    probabilities over the range of the data.\"\"\"\n",
        "\n",
        "    ## get normal distribution best fit\n",
        "    gaussian = scipy.stats.norm(loc=x.mean(), scale=x.std())\n",
        "\n",
        "    ## evaluate over range of data\n",
        "    amp = np.max(np.abs(x.values))\n",
        "    x_eval = np.linspace(-amp, amp)\n",
        "    pdf_eval = gaussian.pdf(x_eval)\n",
        "\n",
        "    return pdf_eval, x_eval\n",
        "\n",
        "\n",
        "def swap_longitude_range(data):\n",
        "    \"\"\"swap longitude range of xr.DataArray from [0,360) to (-180, 180]\"\"\"\n",
        "\n",
        "    ## copy of longitude coordinate to be modified\n",
        "    new_longitude = copy.deepcopy(data.longitude.values)\n",
        "\n",
        "    ## find index where longitude first exceeds 180.\n",
        "    ## (note: np.argmax returns first instance of \"True\" in boolean array)\n",
        "    swap_idx = np.argmax(new_longitude > 180)\n",
        "\n",
        "    ## relabel values >180\n",
        "    new_longitude[swap_idx:] = -360 + new_longitude[swap_idx:]\n",
        "\n",
        "    ## add this coordinate back to the array\n",
        "    data[\"longitude\"] = new_longitude\n",
        "\n",
        "    ## \"roll\" the data to be centered at zero\n",
        "    data = data.roll({\"longitude\": -swap_idx}, roll_coords=True)\n",
        "\n",
        "    return data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "415ebb2c-9aa4-4a7c-babd-47736da795f0",
      "metadata": {
        "editable": true,
        "tags": [],
        "id": "415ebb2c-9aa4-4a7c-babd-47736da795f0"
      },
      "source": [
        "### Region-specific functions"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a26b3b88-e9ba-4a87-abd7-be6adead8eba",
      "metadata": {
        "id": "a26b3b88-e9ba-4a87-abd7-be6adead8eba"
      },
      "source": [
        "```{admonition} To-do: update trimming/plotting functions\n",
        "When implementing your own example, you may need to trim to a different spatial region. You may also want to adjust the region shown in the spatial plot."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a722d3db-b9e9-407f-ac43-32009c2e30a8",
      "metadata": {
        "editable": true,
        "tags": [],
        "id": "a722d3db-b9e9-407f-ac43-32009c2e30a8"
      },
      "outputs": [],
      "source": [
        "def plot_setup_atlantic(fig,lon_range = [-100, 0],\n",
        "                        lat_range = [10, 70]\n",
        "                       ):\n",
        "    \"\"\"Plot Atlantic region\"\"\"\n",
        "\n",
        "    ## adjust figure size\n",
        "    fig.set_size_inches(5, 3)\n",
        "\n",
        "    ## specify map projection\n",
        "    proj = ccrs.Orthographic(central_longitude=int(np.nanmean(lon_range)),\n",
        "                             central_latitude=int(np.nanmean(lat_range))\n",
        "                            )\n",
        "\n",
        "    ## get ax object\n",
        "    ax = plot_setup(\n",
        "        fig,\n",
        "        proj,\n",
        "        lon_range=lon_range,\n",
        "        lat_range=lat_range,\n",
        "        xticks=[-90, -45, 0],\n",
        "        yticks=[0, 35],\n",
        "    )\n",
        "\n",
        "    return fig, ax\n",
        "\n",
        "\n",
        "def plot_setup_woodshole(fig, lon_range=[-75, -60],\n",
        "        lat_range=[35, 45],):\n",
        "    \"\"\"Plot zoomed-in view of Woods Hole\"\"\"\n",
        "\n",
        "    ## adjust figure size\n",
        "    fig.set_size_inches(5, 3)\n",
        "\n",
        "    ## set map projection to orthographic\n",
        "    proj = ccrs.Orthographic(central_longitude=int(np.nanmean(lon_range)),\n",
        "                             central_latitude=int(np.nanmean(lat_range)))\n",
        "\n",
        "    ## Get ax object based on generic plotting function\n",
        "    ax = plot_setup(\n",
        "        fig,\n",
        "        proj,\n",
        "        lon_range=lon_range,\n",
        "        lat_range=lat_range,\n",
        "        xticks=[-73, -68, -63],\n",
        "        yticks=[37, 42],\n",
        "    )\n",
        "\n",
        "    return fig, ax"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8d2660f4-c840-4b9a-9455-7a4fe6f9a32c",
      "metadata": {
        "id": "8d2660f4-c840-4b9a-9455-7a4fe6f9a32c"
      },
      "source": [
        "## Data loading"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f0ac5a12-ff2d-4270-9d6b-2703f2355477",
      "metadata": {
        "id": "f0ac5a12-ff2d-4270-9d6b-2703f2355477"
      },
      "source": [
        "### Data-loading functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c54fc53-4977-44e3-b074-4d7794f63e8a",
      "metadata": {
        "editable": true,
        "tags": [],
        "id": "3c54fc53-4977-44e3-b074-4d7794f63e8a"
      },
      "outputs": [],
      "source": [
        "def load_era5_from_server(server_fp, lon_range, lat_range):\n",
        "    \"\"\"Load ERA5 data from CMIP6 server\"\"\"\n",
        "\n",
        "    ## Filepath to the ERA5 reanalysis\n",
        "    era5_fp = pathlib.Path(\"cmip6/data/era5/reanalysis/single-levels/monthly-means\")\n",
        "\n",
        "    ## sea surface temperature (SST) filepaths\n",
        "    era5_fp_sst = server_fp / era5_fp / pathlib.Path(\"sea_surface_temperature\")\n",
        "\n",
        "    ## open the data\n",
        "    data = xr.open_mfdataset(era5_fp_sst.glob(\"*.nc\"))[\"sst\"]\n",
        "\n",
        "    ## select lon/lat range\n",
        "    lonlat_idx = dict(longitude=slice(*lon_range), latitude=slice(*lat_range[::-1]))\n",
        "    data = data.sel(lonlat_idx).compute()\n",
        "\n",
        "    ## put latitudes in ascending order\n",
        "    data = data.reindex({\"latitude\": data[\"latitude\"].values[::-1]})\n",
        "\n",
        "    return data\n",
        "\n",
        "\n",
        "def load_era5_from_cloud(lon_range, lat_range):\n",
        "    \"\"\"Load ERA5 from Google server\n",
        "    https://weatherbench2.readthedocs.io/en/latest/data-guide.html\n",
        "    \"\"\"\n",
        "\n",
        "    ## open data and get SST\n",
        "    data = xr.open_zarr(\n",
        "        \"gs://weatherbench2/datasets/era5/1959-2023_01_10-6h-240x121_equiangular_with_poles_conservative.zarr\",\n",
        "        chunks=dict(time=1024),\n",
        "    )[\"sea_surface_temperature\"]\n",
        "\n",
        "    ## subset for lon/lat range\n",
        "    lonlat_idx = dict(longitude=slice(*lon_range), latitude=slice(*lat_range))\n",
        "    data = data.sel(**lonlat_idx)\n",
        "\n",
        "    ## load into memory\n",
        "    data.load()\n",
        "\n",
        "    ## resample from 6-hourly to monthly\n",
        "    data = data.resample({\"time\": \"MS\"}).mean()\n",
        "\n",
        "    ## transpose data (consistent with data on server)\n",
        "    data = data.transpose(\"time\", \"latitude\", \"longitude\")\n",
        "\n",
        "    return data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5c785dc5-c09a-41fc-bb18-f02e0e7d6d20",
      "metadata": {
        "editable": true,
        "tags": [],
        "id": "5c785dc5-c09a-41fc-bb18-f02e0e7d6d20"
      },
      "source": [
        "### Load the data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1cf45bcd-077b-46f7-8ae6-1106675dbdc0",
      "metadata": {
        "editable": true,
        "tags": [],
        "id": "1cf45bcd-077b-46f7-8ae6-1106675dbdc0"
      },
      "source": [
        "```{admonition} To-dos\n",
        "1. **Filepath**: update the filepath ```server_fp``` in the code cell below. This is the location of the WHOI CMIP server on your computer (see [server connection setup](../setup/connect_to_server.md) for details).  \n",
        "2. **Longitude/latitude range** (optional): to look at a different region, update the ```lon_range``` and ```lat_range``` parameters in the code cell below (both are set inside of the ```KWARGS``` dictionary)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b11f36d1-959f-4436-9f12-02c083e0af47",
      "metadata": {
        "id": "b11f36d1-959f-4436-9f12-02c083e0af47"
      },
      "source": [
        "````{warning} CMIP server errors\n",
        "The CMIP server seems unable to handle multiple users access the same file at once (e.g., during the actual tutorial session). If you get a mysterious error when trying to load data from the server (e.g., ```NetCDF: HDF error```), try loading the data from the cloud instead (i.e., set ```LOAD_FROM_CLOUD = True``` in the code cell below).\n",
        "\n",
        "In order to load data from Google Cloud storage, you need to install the [```gcsfs```](https://gcsfs.readthedocs.io/en/latest/) and ```zarr``` packages:  \n",
        "```conda install -c conda-forge gcsfs zarr```, or  \n",
        "```mamba install -c conda-forge gcsfs zarr```\n",
        "````"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3fc0dec4-3e6b-4528-9708-1286a9613183",
      "metadata": {
        "editable": true,
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "3fc0dec4-3e6b-4528-9708-1286a9613183",
        "outputId": "eb80780e-14cb-4a6a-c147-5a9050df5a3f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:gcsfs:_request out of retries on exception: Invalid Credentials, 401\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/auth/compute_engine/credentials.py\", line 126, in refresh\n",
            "    self._retrieve_info(request)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/auth/compute_engine/credentials.py\", line 99, in _retrieve_info\n",
            "    info = _metadata.get_service_account_info(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/auth/compute_engine/_metadata.py\", line 338, in get_service_account_info\n",
            "    return get(request, path, params={\"recursive\": \"true\"})\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/auth/compute_engine/_metadata.py\", line 263, in get\n",
            "    raise exceptions.TransportError(\n",
            "google.auth.exceptions.TransportError: (\"Failed to retrieve http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/default/?recursive=true from the Google Compute Engine metadata service. Status: 404 Response:\\nb''\", <google.auth.transport.requests._Response object at 0x7ad573ba98d0>)\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gcsfs/credentials.py\", line 205, in maybe_refresh\n",
            "    self.credentials.refresh(req)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/auth/compute_engine/credentials.py\", line 132, in refresh\n",
            "    raise new_exc from caught_exc\n",
            "google.auth.exceptions.RefreshError: (\"Failed to retrieve http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/default/?recursive=true from the Google Compute Engine metadata service. Status: 404 Response:\\nb''\", <google.auth.transport.requests._Response object at 0x7ad573ba98d0>)\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gcsfs/retry.py\", line 135, in retry_request\n",
            "    return await func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gcsfs/core.py\", line 461, in _request\n",
            "    headers=self._get_headers(headers),\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gcsfs/core.py\", line 438, in _get_headers\n",
            "    self.credentials.apply(out)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gcsfs/credentials.py\", line 217, in apply\n",
            "    self.maybe_refresh()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gcsfs/credentials.py\", line 208, in maybe_refresh\n",
            "    raise HttpError(\n",
            "gcsfs.retry.HttpError: Invalid Credentials, 401\n",
            "ERROR:gcsfs:_request out of retries on exception: Invalid Credentials, 401\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/auth/compute_engine/credentials.py\", line 126, in refresh\n",
            "    self._retrieve_info(request)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/auth/compute_engine/credentials.py\", line 99, in _retrieve_info\n",
            "    info = _metadata.get_service_account_info(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/auth/compute_engine/_metadata.py\", line 338, in get_service_account_info\n",
            "    return get(request, path, params={\"recursive\": \"true\"})\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/auth/compute_engine/_metadata.py\", line 263, in get\n",
            "    raise exceptions.TransportError(\n",
            "google.auth.exceptions.TransportError: (\"Failed to retrieve http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/default/?recursive=true from the Google Compute Engine metadata service. Status: 404 Response:\\nb''\", <google.auth.transport.requests._Response object at 0x7ad573bc0390>)\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gcsfs/credentials.py\", line 205, in maybe_refresh\n",
            "    self.credentials.refresh(req)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/auth/compute_engine/credentials.py\", line 132, in refresh\n",
            "    raise new_exc from caught_exc\n",
            "google.auth.exceptions.RefreshError: (\"Failed to retrieve http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/default/?recursive=true from the Google Compute Engine metadata service. Status: 404 Response:\\nb''\", <google.auth.transport.requests._Response object at 0x7ad573bc0390>)\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gcsfs/retry.py\", line 135, in retry_request\n",
            "    return await func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gcsfs/core.py\", line 461, in _request\n",
            "    headers=self._get_headers(headers),\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gcsfs/core.py\", line 438, in _get_headers\n",
            "    self.credentials.apply(out)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gcsfs/credentials.py\", line 217, in apply\n",
            "    self.maybe_refresh()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gcsfs/credentials.py\", line 208, in maybe_refresh\n",
            "    raise HttpError(\n",
            "gcsfs.retry.HttpError: Invalid Credentials, 401\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "HttpError",
          "evalue": "Invalid Credentials, 401",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTransportError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/auth/compute_engine/credentials.py\u001b[0m in \u001b[0;36mrefresh\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retrieve_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m             self.token, self.expiry = _metadata.get_service_account_token(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/auth/compute_engine/credentials.py\u001b[0m in \u001b[0;36m_retrieve_info\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     98\u001b[0m         \"\"\"\n\u001b[0;32m---> 99\u001b[0;31m         info = _metadata.get_service_account_info(\n\u001b[0m\u001b[1;32m    100\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mservice_account\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_service_account_email\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/auth/compute_engine/_metadata.py\u001b[0m in \u001b[0;36mget_service_account_info\u001b[0;34m(request, service_account)\u001b[0m\n\u001b[1;32m    337\u001b[0m     \u001b[0;31m# for more on the use of 'recursive'.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 338\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"recursive\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"true\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/auth/compute_engine/_metadata.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(request, path, root, params, recursive, retry_count, headers, return_none_for_not_found_error)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m     raise exceptions.TransportError(\n\u001b[0m\u001b[1;32m    264\u001b[0m         \u001b[0;34m\"Failed to retrieve {} from the Google Compute Engine \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTransportError\u001b[0m: (\"Failed to retrieve http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/default/?recursive=true from the Google Compute Engine metadata service. Status: 404 Response:\\nb''\", <google.auth.transport.requests._Response object at 0x7ad573ba98d0>)",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mRefreshError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/gcsfs/credentials.py\u001b[0m in \u001b[0;36mmaybe_refresh\u001b[0;34m(self, refresh_buffer)\u001b[0m\n\u001b[1;32m    204\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcredentials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mgauth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRefreshError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/auth/compute_engine/credentials.py\u001b[0m in \u001b[0;36mrefresh\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0mnew_exc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRefreshError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcaught_exc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mnew_exc\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcaught_exc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRefreshError\u001b[0m: (\"Failed to retrieve http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/default/?recursive=true from the Google Compute Engine metadata service. Status: 404 Response:\\nb''\", <google.auth.transport.requests._Response object at 0x7ad573ba98d0>)",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mHttpError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-11-2647061270.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m## do the data loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mLOAD_FROM_CLOUD\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_era5_from_cloud\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mKWARGS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-10-2832407001.py\u001b[0m in \u001b[0;36mload_era5_from_cloud\u001b[0;34m(lon_range, lat_range)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;31m## open data and get SST\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     data = xr.open_zarr(\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;34m\"gs://weatherbench2/datasets/era5/1959-2023_01_10-6h-240x121_equiangular_with_poles_conservative.zarr\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mchunks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/xarray/backends/zarr.py\u001b[0m in \u001b[0;36mopen_zarr\u001b[0;34m(store, group, synchronizer, chunks, decode_cf, mask_and_scale, decode_times, concat_characters, decode_coords, drop_variables, consolidated, overwrite_encoded_chunks, chunk_store, storage_options, decode_timedelta, use_cftime, zarr_version, zarr_format, use_zarr_fill_value_as_mask, chunked_array_type, from_array_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m   1533\u001b[0m     }\n\u001b[1;32m   1534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1535\u001b[0;31m     ds = open_dataset(\n\u001b[0m\u001b[1;32m   1536\u001b[0m         \u001b[0mfilename_or_obj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstore\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1537\u001b[0m         \u001b[0mgroup\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/xarray/backends/api.py\u001b[0m in \u001b[0;36mopen_dataset\u001b[0;34m(filename_or_obj, engine, chunks, cache, decode_cf, mask_and_scale, decode_times, decode_timedelta, use_cftime, concat_characters, decode_coords, drop_variables, inline_array, chunked_array_type, from_array_kwargs, backend_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m    685\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m     \u001b[0moverwrite_encoded_chunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"overwrite_encoded_chunks\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 687\u001b[0;31m     backend_ds = backend.open_dataset(\n\u001b[0m\u001b[1;32m    688\u001b[0m         \u001b[0mfilename_or_obj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m         \u001b[0mdrop_variables\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdrop_variables\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/xarray/backends/zarr.py\u001b[0m in \u001b[0;36mopen_dataset\u001b[0;34m(self, filename_or_obj, mask_and_scale, decode_times, concat_characters, decode_coords, drop_variables, use_cftime, decode_timedelta, group, mode, synchronizer, consolidated, chunk_store, storage_options, zarr_version, zarr_format, store, engine, use_zarr_fill_value_as_mask, cache_members)\u001b[0m\n\u001b[1;32m   1606\u001b[0m         \u001b[0mfilename_or_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_normalize_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename_or_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1607\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mstore\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1608\u001b[0;31m             store = ZarrStore.open_group(\n\u001b[0m\u001b[1;32m   1609\u001b[0m                 \u001b[0mfilename_or_obj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1610\u001b[0m                 \u001b[0mgroup\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/xarray/backends/zarr.py\u001b[0m in \u001b[0;36mopen_group\u001b[0;34m(cls, store, mode, synchronizer, group, consolidated, consolidate_on_close, chunk_store, storage_options, append_dim, write_region, safe_chunks, zarr_version, zarr_format, use_zarr_fill_value_as_mask, write_empty, cache_members)\u001b[0m\n\u001b[1;32m    730\u001b[0m             \u001b[0mclose_store_on_close\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m             \u001b[0muse_zarr_fill_value_as_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 732\u001b[0;31m         \u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_open_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    733\u001b[0m             \u001b[0mstore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstore\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m             \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/xarray/backends/zarr.py\u001b[0m in \u001b[0;36m_get_open_params\u001b[0;34m(store, mode, synchronizer, group, consolidated, consolidate_on_close, chunk_store, storage_options, zarr_version, use_zarr_fill_value_as_mask, zarr_format)\u001b[0m\n\u001b[1;32m   1809\u001b[0m             \u001b[0;31m# same but with more error handling in case no consolidated metadata found\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1810\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1811\u001b[0;31m                 \u001b[0mzarr_root_group\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzarr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_consolidated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mopen_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1812\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1813\u001b[0m                 \u001b[0;31m# ValueError in zarr-python 3.x, KeyError in 2.x.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/zarr/api/synchronous.py\u001b[0m in \u001b[0;36mopen_consolidated\u001b[0;34m(use_consolidated, *args, **kwargs)\u001b[0m\n\u001b[1;32m    220\u001b[0m     \"\"\"\n\u001b[1;32m    221\u001b[0m     return Group(\n\u001b[0;32m--> 222\u001b[0;31m         \u001b[0msync\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0masync_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_consolidated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_consolidated\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_consolidated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m     )\n\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/zarr/core/sync.py\u001b[0m in \u001b[0;36msync\u001b[0;34m(coro, loop, timeout)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreturn_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseException\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mreturn_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mreturn_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/zarr/core/sync.py\u001b[0m in \u001b[0;36m_runner\u001b[0;34m(coro)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \"\"\"\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mcoro\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/zarr/api/asynchronous.py\u001b[0m in \u001b[0;36mopen_consolidated\u001b[0;34m(use_consolidated, *args, **kwargs)\u001b[0m\n\u001b[1;32m    379\u001b[0m             \u001b[0;34m\"'use_consolidated=False' to bypass consolidated metadata.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m         )\n\u001b[0;32m--> 381\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mopen_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_consolidated\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_consolidated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/zarr/api/asynchronous.py\u001b[0m in \u001b[0;36mopen_group\u001b[0;34m(store, mode, cache_attrs, synchronizer, path, chunk_store, storage_options, zarr_version, zarr_format, meta_array, attributes, use_consolidated)\u001b[0m\n\u001b[1;32m    841\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_READ_MODES\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 843\u001b[0;31m             return await AsyncGroup.open(\n\u001b[0m\u001b[1;32m    844\u001b[0m                 \u001b[0mstore_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzarr_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mzarr_format\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_consolidated\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_consolidated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    845\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/zarr/core/group.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(cls, store, zarr_format, use_consolidated)\u001b[0m\n\u001b[1;32m    548\u001b[0m                 \u001b[0mzattrs_bytes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m                 \u001b[0mmaybe_consolidated_metadata_bytes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m                 \u001b[0;34m(\u001b[0m\u001b[0mstore_path\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mZARR_JSON\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m                 \u001b[0;34m(\u001b[0m\u001b[0mstore_path\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mZGROUP_JSON\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/zarr/storage/_common.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, prototype, byte_range)\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mprototype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m             \u001b[0mprototype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefault_buffer_prototype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprototype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprototype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbyte_range\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbyte_range\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mBuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbyte_range\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mByteRequest\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/zarr/storage/_fsspec.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, key, prototype, byte_range)\u001b[0m\n\u001b[1;32m    298\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbyte_range\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprototype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mawait\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cat_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbyte_range\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRangeByteRequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m                 value = prototype.buffer.from_bytes(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/gcsfs/core.py\u001b[0m in \u001b[0;36m_cat_file\u001b[0;34m(self, path, start, end, **kwargs)\u001b[0m\n\u001b[1;32m   1090\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1091\u001b[0m             \u001b[0mhead\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1092\u001b[0;31m         \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"GET\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1093\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1094\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/gcsfs/core.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, method, path, json_out, info_out, *args, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m     ):\n\u001b[1;32m    476\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{method.upper()}: {path}, {args}, {kwargs.get('headers')}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m         status, headers, info, contents = await self._request(\n\u001b[0m\u001b[1;32m    478\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m         )\n",
            "\u001b[0;32m<decorator-gen-120>\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, method, path, headers, json, data, *args, **kwargs)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/gcsfs/retry.py\u001b[0m in \u001b[0;36mretry_request\u001b[0;34m(func, retries, *args, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mretry\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mretries\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{func.__name__} out of retries on exception: {e}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_retriable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{func.__name__} retrying after exception: {e}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/gcsfs/retry.py\u001b[0m in \u001b[0;36mretry_request\u001b[0;34m(func, retries, *args, **kwargs)\u001b[0m\n\u001b[1;32m    133\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mretry\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m                 \u001b[0;32mawait\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mretry\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m         except (\n\u001b[1;32m    137\u001b[0m             \u001b[0mHttpError\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/gcsfs/core.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, method, path, headers, json, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m    459\u001b[0m             \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m             \u001b[0mjson\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 461\u001b[0;31m             \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_headers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    462\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m             \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequests_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/gcsfs/core.py\u001b[0m in \u001b[0;36m_get_headers\u001b[0;34m(self, headers)\u001b[0m\n\u001b[1;32m    436\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"User-Agent\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m             \u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"User-Agent\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"python-gcsfs/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mversion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 438\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcredentials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/gcsfs/credentials.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, out)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;34m\"\"\"Insert credential headers in-place to a dictionary\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_refresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcredentials\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcredentials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/gcsfs/credentials.py\u001b[0m in \u001b[0;36mmaybe_refresh\u001b[0;34m(self, refresh_buffer)\u001b[0m\n\u001b[1;32m    206\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mgauth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRefreshError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m                     \u001b[0;31m# Re-raise as HttpError with a 401 code and the expected message\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m                     raise HttpError(\n\u001b[0m\u001b[1;32m    209\u001b[0m                         \u001b[0;34m{\u001b[0m\u001b[0;34m\"code\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m401\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"message\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"Invalid Credentials\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     ) from error\n",
            "\u001b[0;31mHttpError\u001b[0m: Invalid Credentials, 401"
          ]
        }
      ],
      "source": [
        "## specify server filepath (only required if loading from server)\n",
        "SERVER_FP = pathlib.Path(\"/Volumes\")\n",
        "\n",
        "## specify whether to load data from cloud\n",
        "LOAD_FROM_CLOUD = True\n",
        "\n",
        "## specify lon/lat range\n",
        "KWARGS = dict(lon_range=[260, 360], lat_range=[10, 70])\n",
        "\n",
        "## keep track of time for data loading\n",
        "t0 = time.time()\n",
        "\n",
        "## do the data loading\n",
        "if LOAD_FROM_CLOUD:\n",
        "    data = load_era5_from_cloud(**KWARGS)\n",
        "\n",
        "else:\n",
        "    data = load_era5_from_server(SERVER_FP, **KWARGS)\n",
        "\n",
        "## print elapsed time\n",
        "print(f\"{time.time() - t0: .1f} seconds\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5c0018c3-7d5f-4194-bcfe-7e4a2a2145da",
      "metadata": {
        "id": "5c0018c3-7d5f-4194-bcfe-7e4a2a2145da"
      },
      "source": [
        "Did you get error ```KeyError or OSError: [Errno -101] NetCDF: HDF error```? Go to FAQ page under the resources section...\n",
        "\n",
        "NOTE: after preventing file locking rewill have to relaunch jupyter from your terminal. Save your changes and close this tab."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "14e7c97f-d676-47ae-a57c-386b79813a9f",
      "metadata": {
        "id": "14e7c97f-d676-47ae-a57c-386b79813a9f"
      },
      "source": [
        "### Plot a sample from the data\n",
        "if you have not installed cmocean you will need to do so (conda/mamba install -c conda-forge cmocean) or swap lines or use \"plasma\" instead of cmo.thermal (ie switch which cmap line is commented out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3438c5e7-8805-4ac9-a18b-2fc1ce5b2b3e",
      "metadata": {
        "id": "3438c5e7-8805-4ac9-a18b-2fc1ce5b2b3e"
      },
      "outputs": [],
      "source": [
        "## blank canvas to plot on\n",
        "fig = plt.figure(layout=\"constrained\")\n",
        "\n",
        "## draw background map of Atlantic\n",
        "fig, ax = plot_setup_atlantic(fig)\n",
        "\n",
        "## plot the data\n",
        "plot_data = ax.contourf(\n",
        "    data.longitude,\n",
        "    data.latitude,\n",
        "    data.isel(time=-1),\n",
        "    transform=ccrs.PlateCarree(),\n",
        "    levels=10,\n",
        "    extend=\"both\",\n",
        "    cmap=\"cmo.thermal\",\n",
        "    # cmap=\"plasma\",\n",
        ")\n",
        "\n",
        "## create colorbath\n",
        "colorbar = fig.colorbar(plot_data, label=r\"$K$\")\n",
        "\n",
        "## Mark Woods Hole on map\n",
        "ax.scatter(\n",
        "    288.5, 41.5, transform=ccrs.PlateCarree(), marker=\"*\", c=\"k\", s=50, zorder=10\n",
        ")\n",
        "\n",
        "## label\n",
        "ax.set_title(f\"SST sample\")\n",
        "\n",
        "## save fig if you would like\n",
        "# fig.savefig(\"Your_directory/sst-sample.svg\")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9c0f4506-d118-4f19-9ad0-bca42d7f853a",
      "metadata": {
        "id": "9c0f4506-d118-4f19-9ad0-bca42d7f853a"
      },
      "source": [
        "## Define an index\n",
        "Next, let's define the \"Woods Hole temperature index\", $T_{wh}$ as the temperature averaged near Woods Hole.\n",
        "\n",
        "```{admonition} To-do: define your own index\n",
        "E.g., choose a different region."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5545657-2a31-447e-be9e-ce79e9ac34a2",
      "metadata": {
        "id": "e5545657-2a31-447e-be9e-ce79e9ac34a2"
      },
      "outputs": [],
      "source": [
        "def compute_T_wh(x):\n",
        "    \"\"\"Compute Woods Hole temperature index\"\"\"\n",
        "\n",
        "    ## define lon/lat range for averaging\n",
        "    ## (note latitude is in descending order in ERA5)\n",
        "    # region = dict(latitude=slice(44, 39), longitude=slice(-72.5, -66.5))\n",
        "    region = dict(latitude=slice(39, 44), longitude=slice(287.5, 293.5))\n",
        "\n",
        "    ## get subset of data inside the box\n",
        "    data_subset = x.sel(region)\n",
        "\n",
        "    ## compute spatial average\n",
        "    return spatial_avg(data_subset)\n",
        "\n",
        "\n",
        "## do the computation here\n",
        "idx = compute_T_wh(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9f147a66-965a-4810-9a92-d8f48c3cdd9b",
      "metadata": {
        "id": "9f147a66-965a-4810-9a92-d8f48c3cdd9b"
      },
      "source": [
        "Let's plot an outline of the region below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "60839e50-f988-4f7e-ad2d-f1125162ae99",
      "metadata": {
        "id": "60839e50-f988-4f7e-ad2d-f1125162ae99"
      },
      "outputs": [],
      "source": [
        "## blank canvas to plot on\n",
        "fig = plt.figure()\n",
        "\n",
        "## draw background map of Atlantic\n",
        "fig, ax = plot_setup_woodshole(fig)\n",
        "\n",
        "## plot the data\n",
        "xx, yy = np.meshgrid(data.longitude.values, data.latitude.values)\n",
        "plot_data = ax.pcolormesh(\n",
        "    xx,\n",
        "    yy,\n",
        "    data.isel(time=-1),\n",
        "    transform=ccrs.PlateCarree(),\n",
        "    # cmap=\"cmo.thermal\",\n",
        "    cmap=\"plasma\",\n",
        ")\n",
        "\n",
        "## create colorbar\n",
        "colorbar = fig.colorbar(plot_data, label=r\"$K$\")\n",
        "\n",
        "## Mark Woods Hole on map\n",
        "ax.scatter(\n",
        "    288.5, 41.5, transform=ccrs.PlateCarree(), marker=\"*\", c=\"k\", s=100, zorder=10\n",
        ")\n",
        "\n",
        "## plot outline of region used to compute index\n",
        "ax = plot_box_outline(ax, lon_range=[-72.5, -66.5], lat_range=[39, 44])\n",
        "\n",
        "## label the plot\n",
        "ax.set_title(f\"SST sample\")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3cb8c620-bc0d-4c40-acc0-5de6acfab816",
      "metadata": {
        "id": "3cb8c620-bc0d-4c40-acc0-5de6acfab816"
      },
      "outputs": [],
      "source": [
        "fig, ax = plot_setup_timeseries()\n",
        "\n",
        "## Plot the data\n",
        "ax.plot(idx.time, idx)\n",
        "\n",
        "## label axes\n",
        "ax.set_title(r\"Woods Hole temperature index\")\n",
        "ax.set_ylabel(r\"$K$\")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "00679d55-29bc-4b04-b1dd-7b3bff4f8b5c",
      "metadata": {
        "id": "00679d55-29bc-4b04-b1dd-7b3bff4f8b5c"
      },
      "source": [
        "## Diagnostics"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "befb97db-d7fd-4302-bef5-64f2fe0877c1",
      "metadata": {
        "id": "befb97db-d7fd-4302-bef5-64f2fe0877c1"
      },
      "source": [
        "### Seasonal cycle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b5a05b7f-c2ff-4d5e-933f-28c5ea399761",
      "metadata": {
        "editable": true,
        "tags": [],
        "id": "b5a05b7f-c2ff-4d5e-933f-28c5ea399761"
      },
      "outputs": [],
      "source": [
        "## compute mean and standard deviation\n",
        "seasonal_mean = idx.groupby(\"time.month\").mean(\"time\")\n",
        "seasonal_std = idx.groupby(\"time.month\").std(\"time\")\n",
        "\n",
        "## make the plot\n",
        "fig, ax = plt.subplots(figsize=(6, 4))\n",
        "\n",
        "# plot mean\n",
        "ax.plot(\n",
        "    seasonal_mean[\"month\"],\n",
        "    seasonal_mean,\n",
        "    label=\"Mean\",\n",
        "    color=\"C0\",\n",
        "    linestyle=\"-\",\n",
        "    linewidth=2,\n",
        ")\n",
        "\n",
        "# Plot shaded std as band (optional)\n",
        "ax.fill_between(\n",
        "    seasonal_mean[\"month\"],\n",
        "    seasonal_mean - seasonal_std,\n",
        "    seasonal_mean + seasonal_std,\n",
        "    color=\"C0\",\n",
        "    alpha=0.3,\n",
        "    label=\"±1 std dev\",\n",
        ")\n",
        "\n",
        "## add some labels\n",
        "ax.set_xticks([1, 4, 8, 12], labels=[\"Jan\", \"Apr\", \"Aug\", \"Dec\"])\n",
        "ax.set_title(r\"$T_{wh}$ climatology\")\n",
        "ax.set_ylabel(r\"$K$\")\n",
        "ax.legend()\n",
        "\n",
        "# fig.savefig(\"your_dir/seasonal-cycle.svg\")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f1f5fb47-d15e-4fe8-bd55-0a5fc5ba5da5",
      "metadata": {
        "id": "f1f5fb47-d15e-4fe8-bd55-0a5fc5ba5da5"
      },
      "source": [
        "### Compute anomalies and linear trend for index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f4b8d66-9681-4bf9-a2ba-79ffb3250f7d",
      "metadata": {
        "id": "2f4b8d66-9681-4bf9-a2ba-79ffb3250f7d"
      },
      "outputs": [],
      "source": [
        "## compute anomalies at gridpoint level, then recompute temperature index\n",
        "data_anom = data.groupby(\"time.month\") - data.groupby(\"time.month\").mean()\n",
        "idx_anom = compute_T_wh(data_anom).compute()\n",
        "\n",
        "## compute linear trend (set deg=2 for quadratic trend)\n",
        "idx_trend = get_trend(idx_anom, deg=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7cb1ae3a-5cf8-4821-8704-f10c04b4299d",
      "metadata": {
        "id": "7cb1ae3a-5cf8-4821-8704-f10c04b4299d"
      },
      "source": [
        "### Next, let's plot the anomalies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d42bd07-31f8-4db4-9525-b6dd27cd24c3",
      "metadata": {
        "id": "9d42bd07-31f8-4db4-9525-b6dd27cd24c3"
      },
      "outputs": [],
      "source": [
        "## setup the plot\n",
        "fig, ax = plot_setup_timeseries()\n",
        "\n",
        "## plot index\n",
        "ax.plot(idx_anom.time, idx_anom)\n",
        "\n",
        "## superimpose trend\n",
        "ax.plot(idx_trend.time, idx_trend, label=\"trend\", c=\"k\")\n",
        "ax.legend()\n",
        "\n",
        "## label plot\n",
        "ax.set_title(r\"$T_{wh}$ anomalies\")\n",
        "ax.set_ylabel(r\"$K$\")\n",
        "\n",
        "# fig.savefig(\"figs/trend.svg\")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6211477e-eeb1-4207-b5c0-77f372bbd4c3",
      "metadata": {
        "id": "6211477e-eeb1-4207-b5c0-77f372bbd4c3"
      },
      "source": [
        "### Histogram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "57f528d6-2895-4df7-9246-613ba7d25527",
      "metadata": {
        "id": "57f528d6-2895-4df7-9246-613ba7d25527"
      },
      "outputs": [],
      "source": [
        "## compute normalized histogram and best-fit Gaussian\n",
        "pdf, pdf_edges = get_empirical_pdf(idx_anom)\n",
        "pdf_gauss, pdf_gauss_pts = get_gaussian_best_fit(idx_anom)\n",
        "\n",
        "#### Plot result\n",
        "fig, ax = plt.subplots(figsize=(4, 3))\n",
        "\n",
        "## plot histogram\n",
        "ax.stairs(values=pdf, edges=pdf_edges)\n",
        "\n",
        "## plot gaussian\n",
        "x = np.linspace(-3, 3)\n",
        "ax.plot(pdf_gauss_pts, pdf_gauss, c=\"k\")\n",
        "\n",
        "## label\n",
        "ax.set_xlabel(r\"$K$ anomaly\")\n",
        "ax.set_ylabel(\"Probability\")\n",
        "\n",
        "## save to file\n",
        "# fig.savefig(\"figs/histogram.svg\")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5d780a04-77ef-4a3e-9ad3-cccff99e0715",
      "metadata": {
        "id": "5d780a04-77ef-4a3e-9ad3-cccff99e0715"
      },
      "source": [
        "#### Power spectral density (PSD)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a715c5d6-adf9-409d-840a-fff99f340e5a",
      "metadata": {
        "id": "a715c5d6-adf9-409d-840a-fff99f340e5a"
      },
      "outputs": [],
      "source": [
        "## compute PSD\n",
        "## 'fs' is sampling frequency (units: samples/year)\n",
        "freq, psd = scipy.signal.welch(idx_anom.values, fs=12)\n",
        "\n",
        "## plot result\n",
        "fig, ax = plt.subplots(figsize=(4, 3))\n",
        "ax.loglog(freq, psd)\n",
        "ax.set_xlabel(\"Freq (1/year)\")\n",
        "ax.set_ylabel(r\"PSD (variance $\\cdot$ year)\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "def80682-17d9-45ae-809f-02d2be3da705",
      "metadata": {
        "id": "def80682-17d9-45ae-809f-02d2be3da705"
      },
      "source": [
        "### Spatial correlation\n",
        "(between index and spatial data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b2fd06e5-d888-4d97-bf9d-eec477ac8f7c",
      "metadata": {
        "id": "b2fd06e5-d888-4d97-bf9d-eec477ac8f7c"
      },
      "outputs": [],
      "source": [
        "## compute correlation (detrend data first)\n",
        "corr = xr.corr(detrend(data_anom), detrend(idx_anom), dim=\"time\")\n",
        "\n",
        "## Make plot\n",
        "fig, ax = plot_correlation(\n",
        "    plot_setup_fn=plot_setup_atlantic, corr=corr, x=corr.longitude, y=corr.latitude\n",
        ")\n",
        "\n",
        "## Mark Woods Hole on map\n",
        "ax.scatter(\n",
        "    288.5, 41.5, transform=ccrs.PlateCarree(), marker=\"*\", c=\"magenta\", s=50, zorder=10\n",
        ")\n",
        "\n",
        "## label\n",
        "ax.set_title(r\"Correlation with $T_{wh}$\")\n",
        "\n",
        "## save to file\n",
        "# fig.savefig(\"figs/spatial-correlation.svg\")\n",
        "\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.12"
    },
    "colab": {
      "provenance": [],
      "name": "data_analysis_ERA5-cloud_colab.ipynb",
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}